


Languages = Python , Scala

SQl = Postgres , Redshift , Snwoflake

NoSQL = MongoDB ,

Short Storage = Redis ,


Orchestration tools  = Airflow , Prefect , Dagster , Mage ai

Data Viz = Tableau , Power BI , Looker , Mode , Metabase , 

Cloud  =  AWS , Azure , GCP

Big Data = Hadoop , Spark , Hive ,  Hbase , Kafka , Flink ,


Aws =  S3 , EC2 , Elasticsearch , Redshift , Athena , Glue , EMR , Lambda ,  DynamoDB , Cloudwatch , 

FilestorageType = csv , json , Parquet , Avro , ORC 

ETL = Pentaho , Informatica


Data source =  Kafka , DB(MongoDB) , SQL(Mysql) 


Data Transformation  = Python ( pandas , s3 )

Data Loading = (Redshift ( COPY Commnad))

Upsert Modes (where not in main table (insert)) else (update set )

Data Quality =  (Data Validation , Data Profiling , Data Quality Rules) (Great Expectations)


(MongoDB , Postgres , SNowflake)